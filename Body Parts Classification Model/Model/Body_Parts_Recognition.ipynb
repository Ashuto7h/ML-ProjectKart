{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGBF9Yuf25Oa",
        "outputId": "29b982c9-efca-4283-e3c4-be44be40158f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n",
        "!chmod 600 !/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2U6J8Zp3QJg",
        "outputId": "b82e7290-5481-4a91-cbab-de39b83aa8cf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chmod: cannot access '!/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import kaggle\n",
        "\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/root/.kaggle/'\n",
        "kaggle.api.authenticate()\n",
        "\n",
        "kaggle.api.dataset_download_files('linkanjarad/body-parts-dataset', unzip=True)"
      ],
      "metadata": {
        "id": "Y17-WYiM3vNC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Body Parts Recognition Model\n",
        "\n",
        "- Dataset from Kaggle [Link](https://www.kaggle.com/datasets/linkanjarad/body-parts-dataset)."
      ],
      "metadata": {
        "id": "oIXO8o6KMt8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "DMa0UV4W4XAO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A function which build 2 seprate sets i.e., Training and testing sets."
      ],
      "metadata": {
        "id": "wk6K4vz6Mz1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def buildDataset(name):\n",
        "    names = []\n",
        "    sourcePath = f'/content/Body Parts Dataset/{name}'\n",
        "\n",
        "    # Check if the source directory exists\n",
        "    if not os.path.exists(sourcePath):\n",
        "        print(f\"Source directory '{sourcePath}' does not exist.\")\n",
        "        return\n",
        "\n",
        "    # Create the destination directories if they don't exist\n",
        "    trainPath = f'/content/dataset/train/{name}'\n",
        "    testPath = f'/content/dataset/test/{name}'\n",
        "\n",
        "    os.makedirs(trainPath, exist_ok=True)\n",
        "    os.makedirs(testPath, exist_ok=True)\n",
        "\n",
        "    for filename in os.listdir(sourcePath):\n",
        "        names.append(filename)\n",
        "\n",
        "    # Shuffling of the whole dataset\n",
        "    random.shuffle(names)\n",
        "\n",
        "    # Split dataset into train and test set\n",
        "    train = names[0: int(0.8*len(names))]\n",
        "    test = names[int(0.8*len(names)): len(names)+1]\n",
        "\n",
        "    # Store the prepared data into separate dataset folder\n",
        "    # Storing the training dataset\n",
        "    for i in train:\n",
        "        filePath = os.path.join(sourcePath, i)\n",
        "        img = cv2.imread(filePath)\n",
        "        cv2.imwrite(os.path.join(trainPath, i), img)\n",
        "\n",
        "    # Storing the testing dataset\n",
        "    for i in test:\n",
        "        filePath = os.path.join(sourcePath, i)\n",
        "        img = cv2.imread(filePath)\n",
        "        cv2.imwrite(os.path.join(testPath, i), img)"
      ],
      "metadata": {
        "id": "P9uMBw9R7Msa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ['Belly', 'Ear', 'Elbow', 'Eye', 'Foot', 'Hand', 'Knee', 'Neck', 'Nose', 'Shoulders']\n",
        "\n",
        "# Building the train and test dataset for model training.\n",
        "for name in dataset:\n",
        "  buildDataset(name)"
      ],
      "metadata": {
        "id": "u65WosNN-bJD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path of the train and test dataset\n",
        "trainPath = '/content/dataset/train'\n",
        "testPath = '/content/dataset/test'"
      ],
      "metadata": {
        "id": "uRn0OYfw-8Pc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Refactoring the images and scale them to fit for the model."
      ],
      "metadata": {
        "id": "vlbve4jzM9Bu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = ImageDataGenerator(rescale = 1.0/255.0)\n",
        "\n",
        "# Normalise the train dataset\n",
        "trainImageGenerator = generator.flow_from_directory(trainPath,\n",
        "                                                   target_size=(150, 150),\n",
        "                                                   batch_size=32,\n",
        "                                                   class_mode='categorical')\n",
        "\n",
        "# Normalise the test dataset\n",
        "testImageGenerator = generator.flow_from_directory(testPath,\n",
        "                                                   target_size=(150, 150),\n",
        "                                                   batch_size=32,\n",
        "                                                   class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqmUpe83_kBt",
        "outputId": "e1809d44-955c-4509-b67d-4bf71c1b748b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1669 images belonging to 10 classes.\n",
            "Found 423 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classMap = dict([v, k] for k, v in trainImageGenerator.class_indices.items())\n",
        "print(classMap)"
      ],
      "metadata": {
        "id": "DcCGZ6NXASjq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23be6ea4-ede7-483c-cc9e-53373a78dc6d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'Belly', 1: 'Ear', 2: 'Elbow', 3: 'Eye', 4: 'Foot', 5: 'Hand', 6: 'Knee', 7: 'Neck', 8: 'Nose', 9: 'Shoulders'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the model.\n",
        "- Start with Convolution layers.\n",
        "- Then Maxpooling layers.\n",
        "- After a neural network, Creating a Fully-connected layers.\n",
        "- Now, flatten all the layers in a single dimenstion to create a Fully-connected layers.\n",
        "- There is a Dropout layer in between the Fully-connected layers."
      ],
      "metadata": {
        "id": "3y9CCYptNFUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=[150, 150, 3]))\n",
        "model.add(MaxPooling2D(2,))\n",
        "model.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2))\n",
        "\n",
        "# Flatten the feature map\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add the fully connected layers\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# print(the model summary)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9Muy0j-KYY7",
        "outputId": "cbe67235-c769-4796-c939-cdac4178d0fa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 150, 150, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 75, 75, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 75, 75, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 37, 37, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 87616)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               11214976  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11252170 (42.92 MB)\n",
            "Trainable params: 11252170 (42.92 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compiling the model on **Adam** Optimizer with **Categorical Crossentropy** loss function."
      ],
      "metadata": {
        "id": "z7NRfkLXNJEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics='accuracy')"
      ],
      "metadata": {
        "id": "h53smiFzLJLa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model training begins"
      ],
      "metadata": {
        "id": "dBrX4KUgNUvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(trainImageGenerator, epochs=15, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqqzRkXtLZY_",
        "outputId": "3a57fdf8-5775-475d-93e6-db5ef406a974"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "53/53 [==============================] - 10s 64ms/step - loss: 2.6138 - accuracy: 0.1246\n",
            "Epoch 2/15\n",
            "53/53 [==============================] - 5s 93ms/step - loss: 2.1944 - accuracy: 0.2157\n",
            "Epoch 3/15\n",
            "53/53 [==============================] - 3s 60ms/step - loss: 1.9262 - accuracy: 0.3355\n",
            "Epoch 4/15\n",
            "53/53 [==============================] - 2s 32ms/step - loss: 1.5440 - accuracy: 0.5087\n",
            "Epoch 5/15\n",
            "53/53 [==============================] - 2s 34ms/step - loss: 1.1049 - accuracy: 0.6411\n",
            "Epoch 6/15\n",
            "53/53 [==============================] - 2s 44ms/step - loss: 0.7519 - accuracy: 0.7591\n",
            "Epoch 7/15\n",
            "53/53 [==============================] - 3s 50ms/step - loss: 0.4958 - accuracy: 0.8466\n",
            "Epoch 8/15\n",
            "53/53 [==============================] - 2s 32ms/step - loss: 0.3332 - accuracy: 0.9041\n",
            "Epoch 9/15\n",
            "53/53 [==============================] - 2s 32ms/step - loss: 0.2537 - accuracy: 0.9209\n",
            "Epoch 10/15\n",
            "53/53 [==============================] - 2s 32ms/step - loss: 0.2069 - accuracy: 0.9437\n",
            "Epoch 11/15\n",
            "53/53 [==============================] - 2s 31ms/step - loss: 0.1558 - accuracy: 0.9587\n",
            "Epoch 12/15\n",
            "53/53 [==============================] - 2s 36ms/step - loss: 0.1232 - accuracy: 0.9646\n",
            "Epoch 13/15\n",
            "53/53 [==============================] - 3s 50ms/step - loss: 0.1080 - accuracy: 0.9718\n",
            "Epoch 14/15\n",
            "53/53 [==============================] - 2s 32ms/step - loss: 0.1173 - accuracy: 0.9664\n",
            "Epoch 15/15\n",
            "53/53 [==============================] - 2s 32ms/step - loss: 0.1053 - accuracy: 0.9730\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cb2b5bd4b50>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.evaluate(trainImageGenerator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OQOyyprLwCf",
        "outputId": "52c13061-2d95-4b2e-8b39-9ac3d8643aa1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 [==============================] - 2s 29ms/step - loss: 0.0137 - accuracy: 0.9964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy: {:.2f}%'.format(history[1] * 100))\n",
        "print('Loss: {:.2f}%'.format(history[0] * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEXx9MFvL5tU",
        "outputId": "638aa892-fd91-42c6-f90d-7735d781ace7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 99.64%\n",
            "Loss: 1.37%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Ready with 99.64% Accuracy."
      ],
      "metadata": {
        "id": "WY85VQzXMgZq"
      }
    }
  ]
}